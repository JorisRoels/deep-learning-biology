{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSg5U4D5I35S"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JorisRoels/deep-learning-biology/blob/main/exercises/assignments/2020-dlb-3-cnn-segmentation.ipynb)\n",
    "\n",
    "# Exercise 3: Convolutional neural networks for segmentation\n",
    "\n",
    "In this notebook, we will be using convolutional neural networks for segmentation of neurons in electron microscopy data. \n",
    "\n",
    "The structure of these exercises is as follows: \n",
    "\n",
    "1. [Import libraries and download data](#scrollTo=ScagUEMTMjlK)\n",
    "2. [Data visualization and pre-processing](#scrollTo=ohZHyOTnI35b)\n",
    "3. [Segmentation: a pixel classification problem](#scrollTo=UyspYtez5J8a)\n",
    "4. [Building a U-Net with PyTorch](#scrollTo=wXbjn29WOOJ3)\n",
    "5. [Training & validating the network](#scrollTo=zh8Pf_3HF_hi)\n",
    "\n",
    "This notebook is largely based on the research published in: \n",
    "\n",
    "Arganda-Carreras, I., Turaga, S. C., Berger, D. R., Ciresan, D. C., Giusti, A., Gambardella, L. M., Schmidhuber, J., Laptev, D., Dwivedi, S., Buhmann, J. M., Liu, T., Seyedhosseini, M., Tasdizen, T., Kamentsky, L., Burget, R., Uher, V., Tan, X., Sun, C., Pham, T. D., â€¦ Seung, H. S. (2015). Crowdsourcing the creation of image segmentation algorithms for connectomics. Frontiers in Neuroanatomy, 9. https://doi.org/10.3389/fnana.2015.00142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScagUEMTMjlK"
   },
   "source": [
    "## 1. Import libraries and download data\n",
    "Let's start with importing the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dS4jDyCl09w8"
   },
   "outputs": [],
   "source": [
    "!pip install neuralnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1oGi88ZU8eN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from progressbar import ProgressBar, Percentage, Bar, ETA, FileTransferSpeed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "import progressbar\n",
    "import time\n",
    "\n",
    "from neuralnets.util.io import read_tif\n",
    "from neuralnets.util.visualization import overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIPng9wbV-Zs"
   },
   "source": [
    "As you will notice, Colab environments come with quite a large library pre-installed. If you need to import a module that is not yet specified, you can add it in the previous cell (make sure to run it again). If the module is not installed, you can install it with `pip`. \n",
    "\n",
    "To make your work reproducible, it is advised to initialize all modules with stochastic functionality with a fixed seed. Re-running this script should give the same results as long as the seed is fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OOFPFLiV-mh"
   },
   "outputs": [],
   "source": [
    "# make sure the results are reproducible\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# run all computations on the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running computations with %s' % torch.device(device))\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjfnM2ffU9G0"
   },
   "source": [
    "We will now download the required data from a public Google Drive repository. The data is stored as a zip archive and automatically extracted to the `data` directory in the current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ilt9ZM3I35T"
   },
   "outputs": [],
   "source": [
    "# fields\n",
    "url = 'http://data.bits.vib.be/pub/trainingen/DeepLearning/data-3.zip'\n",
    "cmp_data_path = 'data.zip'\n",
    "\n",
    "# download the compressed data\n",
    "gdown.download(url, cmp_data_path, quiet=False)\n",
    "\n",
    "# extract the data\n",
    "zip = zipfile.ZipFile(cmp_data_path)\n",
    "zip.extractall('')\n",
    "\n",
    "# remove the compressed data\n",
    "os.remove(cmp_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohZHyOTnI35b"
   },
   "source": [
    "## 2. Data visualization and pre-processing\n",
    "\n",
    "The data used for this exercise session originates from an ISBI segmentation challenge on neuron structures in electron microscopy image stacks. The organizers provide a training volume and their corresponding labels. The test set is also provided, however predictions can be validated by uploading them to the challenge central server. This is to avoid overfitting the model on the test set. \n",
    "\n",
    "Each data volume is provided as a .tif file that contains a 3D array. For the input data, these are simply the intensity values measured by the microscope. For the labels, this is a binary value: 0 for membrane, 255 for inner neuron structure. \n",
    "\n",
    "We briefly visualize the labeled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hJjZQEGI35f"
   },
   "outputs": [],
   "source": [
    "# specify where the data is stored\n",
    "data_dir = 'data-3'\n",
    "\n",
    "# load the datadispensers\n",
    "x = read_tif(os.path.join(data_dir, 'train-volume.tif'))\n",
    "y = read_tif(os.path.join(data_dir, 'train-labels.tif'))\n",
    "\n",
    "# print out size\n",
    "print('Size of the labeled volume: %d x %d x %d' % x.shape)\n",
    "\n",
    "# show example\n",
    "x_overlay = overlay(x[0] / 255, 1-(y[0]>0), colors=[(1, 0, 0)], alpha=0.4)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "plt.title('Input data')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(y[0], cmap='gray')\n",
    "plt.title('Labels')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(x_overlay)\n",
    "plt.title('Membrane overlay')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1mgwBNZ3kY7"
   },
   "source": [
    "Annotation of datasets like this typically involve lots of expertise and manual labour and is therefore extremely costly. This is a general issue in biomedical image-based datasets. For this reason, there has been increasing attention in developing automated segmentation techniques for biomedical imaging datasets. In the following, you will see how deep learning models can achieve relatively high accuracy on complex task such as neuronal structure segmentation. \n",
    "\n",
    "As in practically any image analysis application, it is good common practice to rescale the data to the [0,1] interval, map the labels to subsequent values (0 and 1 in this case) and split the data in a train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p8ZkUfD7L6g"
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "# map the 255 labels to 1\n",
    "y[y == 255] = 1\n",
    "\n",
    "# split the data in a train and test set\n",
    "test_ratio = 0.33 # we will use 33% of the data for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_ratio, random_state=seed)\n",
    "\n",
    "# print out size\n",
    "print('Training volume: %d x %d x %d' % x_train.shape)\n",
    "print('Testing volume: %d x %d x %d' % x_test.shape)\n",
    "\n",
    "# \n",
    "class_distribution = [np.sum(y_train == 0) / y_train.size, np.sum(y_train == 1) / y_train.size]\n",
    "print('Class balance: ' )\n",
    "print('    0: %.3f' % class_distribution[0])\n",
    "print('    1: %.3f' % class_distribution[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyspYtez5J8a"
   },
   "source": [
    "## 3. Segmentation: a pixel classification problem\n",
    "\n",
    "From a machine learning point of view, image segmentation can be seen as a classification problem. For each pixel in the image, the goal is to predict the corresponding class (membrane or non-membrane). Up to 2012, most techniques were based on extracting a set of features from a local or global region (e.g. intensity, edges, etc.) around the pixel and training a shallow classifier (e.g. a random forest). The choice of features would typically be the crucial factor and is different for each application. \n",
    "\n",
    "Convolutional neural networks however, are able to solve this issue, as the feature extractor is learned based on the training data. To do this, we have to do two things: implement a dataset that extracts a local window for each pixel and train a CNN that performs binary classification. Let's start with the dataset. \n",
    "\n",
    "**Exercise**: Implement the `EMWindowDataset` class:  \n",
    "- The `__init__` function should save the inputs and labels\n",
    "- The `__getitem__` function should return a local window around the i'th pixel (use slice-by-slice raster ordering for this) and the corresponding label of that pixel. Note that extracting local windows near the bounds of the image may result in out-of-bound errors. You can omit this by [padding](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) the data. \n",
    "- The `__len__` function should ideally return the amount of pixels in the data. However, a single epoch would then require lots of iterations. Cap this with an upper bound `max_iter_epoch`. \n",
    "- Data augmentation is not yet required. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFyL6SBv_fZZ"
   },
   "outputs": [],
   "source": [
    "# helper function: transform a linear index from a 3D array to 3D coordinates\n",
    "# assuming slice-by-slice raster scanning ordering\n",
    "def delinearize_index(i, sz):\n",
    "    z_, y_, x_ = sz\n",
    "    x = np.mod(i, x_)\n",
    "    j = (i - x) // x_\n",
    "    y = np.mod(j, y_)\n",
    "    z = (j - y) // y_\n",
    "    return z, y, x\n",
    "\n",
    "# dataset useful for sampling (and many other things)\n",
    "class EMWindowDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y, wnd_sz, max_iter_epoch):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "# parameters\n",
    "window_size = (32, 32)\n",
    "batch_size = 256\n",
    "max_iter_epoch = 2**12\n",
    "\n",
    "# make an instance of the dataset for training and testing\n",
    "ds_train = EMWindowDataset(x_train, y_train, window_size, max_iter_epoch)\n",
    "ds_test = EMWindowDataset(x_test, y_test, window_size, max_iter_epoch)\n",
    "\n",
    "# test the class\n",
    "n = np.random.randint(len(ds_train))\n",
    "wnd, label = ds_train[n]\n",
    "plt.imshow(wnd[0], cmap='gray')\n",
    "plt.title(label)\n",
    "plt.show()\n",
    "\n",
    "# setup the data loader\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89tJUGcFh5W4"
   },
   "source": [
    "The positive side to segmentation labels is that each pixel corresponds to a single annotation. In contrast to usual classification dataset, this may give the impression that there are lots of labels. However, keep in mind that the data is heavily correlated, especially locally. In other words, neighboring pixel labels of a reference pixel won't provide that much more information than the reference pixel label. \n",
    "\n",
    "The classification network that we will use is exactly the same as the one we used in the previous session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_Hqi2uvem87"
   },
   "outputs": [],
   "source": [
    "class ConvNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ConvNormRelu, self).__init__()\n",
    "        self.unit = nn.Sequential()\n",
    "        self.unit.add_module('conv', nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding))\n",
    "        self.unit.add_module('norm', nn.BatchNorm2d(int(out_channels)))\n",
    "        self.unit.add_module('activation', nn.ReLU())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.unit(inputs)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, feature_maps=16):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.feature_maps = feature_maps\n",
    "\n",
    "        self.conv1 = ConvNormRelu(in_channels=1, out_channels=feature_maps)\n",
    "        self.conv2 = ConvNormRelu(in_channels=feature_maps, out_channels=feature_maps)\n",
    "        self.conv3 = ConvNormRelu(in_channels=feature_maps, out_channels=feature_maps)\n",
    "        self.conv4 = ConvNormRelu(in_channels=feature_maps, out_channels=feature_maps)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(feature_maps*2*2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = self.pool(self.conv3(x))\n",
    "        x = self.pool(self.conv4(x))\n",
    "        x = x.view(-1, self.feature_maps*2*2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CNN(feature_maps=16)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgQTXcv4jlii"
   },
   "source": [
    "We will use an alternative metric for validation. The accuracy is a metric motivated from a classification point of view. A more suitable segmentation metric is the Dice coefficient: \n",
    "\n",
    "$$\n",
    "D = \\frac{2 \\times \\left| Y \\cap \\hat{Y} \\right|}{\\left| Y \\right| + \\left| \\hat{Y} \\right|}\n",
    "$$\n",
    "\n",
    "where $Y$ and $\\hat{Y}$ are the ground truth and predicted segmentation, respectively. If the prediction perfectly overlaps, the Dice coefficient will be 1. The code below illustrates the resulting segmentation of the best model so far and the corresponding dice score. \n",
    "\n",
    "**Exercise**: Train the classification network for pixel-wise label prediction:  \n",
    "- Implement the `train_net`, `train_epoch` and `test_epoch`. To make life easier, you can reuse parts of the code of the previous exercise. \n",
    "- Implement the `dice` function that computes the metric describe above. Save the model with the highest Dice score (averaged over the two classes). \n",
    "- Evaluate the (average) Dice metric at the end of each test epoch and save it, so that it can be plotted (similar to the loss). \n",
    "- Train the network for 20 epochs at a learning rate of 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2edDXq0jzJn"
   },
   "outputs": [],
   "source": [
    "# dice coefficient implementation\n",
    "def dice(y, y_pred):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# implementation of a single training epoch\n",
    "def train_epoch(net, loader, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# implementation of a single testing epoch\n",
    "def test_epoch(net, loader, loss_fn):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "def train_net(net, train_loader, test_loader, loss_fn, optimizer, epochs, log_dir):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    return train_loss, test_loss, test_dice\n",
    "\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "n_epochs = 20\n",
    "log_dir = '.'\n",
    "\n",
    "# define the optimizer\n",
    "class_weights = torch.from_numpy(np.divide(1, class_distribution)).float().to(device)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# start training\n",
    "train_loss_cnn, test_loss_cnn, test_dice_cnn = train_net(net, train_loader, test_loader, loss_fn, optimizer, n_epochs, log_dir)\n",
    "\n",
    "# show the training curve and accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_cnn)\n",
    "plt.plot(test_loss_cnn)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(('Train', 'Test'))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_dice_cnn)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice avg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EoE3gYOxYmj"
   },
   "source": [
    "You should obtain an average Dice score between 0.70 and 0.75. However, note that according to the learning curves, the model seems to be overfitting relatively fast. This is mainly due to the locality of the feature extraction. We will now illustrate how a test sample can be segmented with the trained network. \n",
    "\n",
    "**Exercise**: Implement the `segment_slice` function: \n",
    "- The function takes a 2D slice, a pretrained network, a window size and batch size as input, and computes the segmentation (a binary 2D array). \n",
    "- The easiest way to loop through all the pixels of an image is by using the `EMWindowDataset` without shuffling. However, you will have to adjust the maximum number of iterations. \n",
    "- As a first step, you can assume `batch_size=1`. Keep in mind, this can be inefficient, because GPUs become beneficial as the amount of parallel operations increases. Higher batch sizes therefore benefit computing time, but this is of course bounded to the available GPU memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ohd9b7A4kmkv"
   },
   "outputs": [],
   "source": [
    "def segment_slice(x, net, window_size, batch_size):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# load the best parameters\n",
    "state_dict = torch.load('cnn_best.cpt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# perform segmentation\n",
    "n = 0\n",
    "t = time.time()\n",
    "y_pred = segment_slice(x_test[n], net, window_size, batch_size)\n",
    "print('Elapsed time: %.2f seconds' % (time.time() - t))\n",
    "\n",
    "# show example\n",
    "x_overlay = overlay(x_test[n], 1 - y_test[n], colors=[(1, 0, 0)], alpha=0.4)\n",
    "x_pred_overlay = overlay(x_test[n], 1 - y_pred, colors=[(1, 0, 0)], alpha=0.4)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_pred_overlay)\n",
    "plt.title('Predictions')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_overlay)\n",
    "plt.title('Labels')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImvF5mxu81o9"
   },
   "source": [
    "Visually, the segmentation result does not look perfect. Clearly, the network is making lots of mistakes, especially along membranes, because these regions require more context. \n",
    "\n",
    "Another disadvantage to this methodology is the computational inefficiency. Even with larger batches, segmentation of a relatively small image patch can take seconds, which is impractical for larger datasets. The reason is obviously that for each pixel, a forward call of the network is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXbjn29WOOJ3"
   },
   "source": [
    "## 4. Building a U-Net with PyTorch\n",
    "\n",
    "The lack of global context and computational efficiency of the pixel classification approach results in poor practical performance. As an alternative, the [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) network was proposed. This is an end-to-end segmentation network that takes an image as input and computes a complete segmentation of the input. Let's start by defining the network architecture: \n",
    "\n",
    "![U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
    "\n",
    "**Exercise**: Implement the U-Net architecture: \n",
    "- The architecture consists of an encoder, a bottleneck, a decoder and skip connections between the encoder and decoder. \n",
    "- The basic building blocks of the U-Net architecture are two consecutive convolutional layers with ReLU activation that take $n$ feature maps and output $m$ feature maps. The convolutional layers have $3 \\times 3$ kernels. For simplicity we will also pad the inputs by 1 pixel to make sure the inputs and outputs have the same size. Implement this block in the `ConvBlock` class. \n",
    "- Downsampling is relatively simply with $2 \\times 2$ max-pooling. However, upsampling is performed using bilinear upsampling layers, followed by a convolution layer. This operation has been implemented in the [`ConvTranspose2d`](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) class with $2 \\times 2$ kernels and a stride of $2$. \n",
    "- Implement the skip connections by using the PyTorch [concatenation](https://pytorch.org/docs/stable/generated/torch.cat.html) function. \n",
    "- The initial number of feature maps is a parameter that can be chosen. From then on, the amount of feature maps doubles with every `ConvBlock` in the encoder and halves with every `ConvBlock` in the decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbCTjS-2426r"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, feature_maps=16, out_channels=2):\n",
    "        super(UNet, self).__init__()\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "net = UNet(feature_maps=64)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJyJp-ovFUuB"
   },
   "source": [
    "Of course, this network requires an image as input and the corresponding label image as output. Therefore, we have to modify our dataset. \n",
    "\n",
    "**Exercise**: Modify the `EMWindowDataset` class: \n",
    "- Implement the `__getitem__` method, the remaining functions have already been implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHV8fP50bdmO"
   },
   "outputs": [],
   "source": [
    "# dataset useful for sampling\n",
    "class EMWindowDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y, wnd_sz, max_iter_epoch):\n",
    "\n",
    "        # window size\n",
    "        self.wnd_sz = wnd_sz\n",
    "\n",
    "        # maximum number of iterations per epoch\n",
    "        self.max_iter_epoch = max_iter_epoch\n",
    "\n",
    "        # save the data\n",
    "        self.x = x\n",
    "\n",
    "        # save the labels\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.max_iter_epoch\n",
    "\n",
    "# parameters\n",
    "window_size = (128, 128)\n",
    "batch_size = 2\n",
    "max_iter_epoch = 128\n",
    "\n",
    "# make an instance of the dataset for training and testing\n",
    "ds_train = EMWindowDataset(x_train, y_train, window_size, max_iter_epoch)\n",
    "ds_test = EMWindowDataset(x_test, y_test, window_size, max_iter_epoch)\n",
    "\n",
    "# test the class\n",
    "n = np.random.randint(len(ds_train))\n",
    "x, y = ds_train[n]\n",
    "x_overlay = overlay(x[0], 1 - y[0], colors=[(1, 0, 0)], alpha=0.4)\n",
    "plt.imshow(x_overlay)\n",
    "plt.show()\n",
    "\n",
    "# setup the data loader\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh8Pf_3HF_hi"
   },
   "source": [
    "## 5. Training & validating the network\n",
    "\n",
    "Now that we have a U-Net network and a data loader, it is time to train the network! For the sake of repetitiveness, you are not required to implement the complete training loop. \n",
    "\n",
    "**Exercise**: Train the U-Net architecture: \n",
    "- Have a look at the training loop code and identify the differences with classical CNN training. \n",
    "- Train the network for 20 epochs with a learning rate of 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIb7dtTxfAE2"
   },
   "outputs": [],
   "source": [
    "# implementation of a single training epoch\n",
    "def train_epoch(net, loader, loss_fn, optimizer):\n",
    "    \n",
    "    # set the network in training mode\n",
    "    net.train()\n",
    "    \n",
    "    # keep track of the loss\n",
    "    loss_cum = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, data in enumerate(loader): \n",
    "        \n",
    "        # sample data\n",
    "        x, y = data\n",
    "\n",
    "        # transfer data to GPU and correct format\n",
    "        x = x.float().to(device)\n",
    "        y = y.long()[:, 0, :, :].to(device)\n",
    "        \n",
    "        # set all gradients equal to zero\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # feed the batch to the network and compute the outputs\n",
    "        y_pred = net(x)\n",
    "        \n",
    "        # compare the outputs to the labels with the loss function\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_cum += loss.data.cpu().numpy()\n",
    "        cnt += 1\n",
    "        \n",
    "        # backpropagate the gradients w.r.t. computed loss\n",
    "        loss.backward()\n",
    "\n",
    "        # apply one step in the optimization\n",
    "        optimizer.step()\n",
    "    \n",
    "    # compute the average loss\n",
    "    loss_avg = loss_cum / cnt\n",
    "    \n",
    "    return loss_avg\n",
    "\n",
    "# implementation of a single testing epoch\n",
    "def test_epoch(net, loader, loss_fn):\n",
    "    \n",
    "    # set the network in training mode\n",
    "    net.eval()\n",
    "    \n",
    "    # keep track of the loss and predictions\n",
    "    preds = np.zeros((len(loader.dataset), *loader.dataset.wnd_sz))\n",
    "    ys = np.zeros((len(loader.dataset), *loader.dataset.wnd_sz))\n",
    "    loss_cum = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, data in enumerate(loader): \n",
    "        \n",
    "        # sample data\n",
    "        x, y = data\n",
    "\n",
    "        # transfer data to GPU and correct format\n",
    "        x = x.float().to(device)\n",
    "        y = y.long()[:, 0, :, :].to(device)\n",
    "        \n",
    "        # feed the batch to the network and compute the outputs\n",
    "        y_pred = net(x)\n",
    "        \n",
    "        # compare the outputs to the labels with the loss function\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_cum += loss.data.cpu().numpy()\n",
    "        cnt += 1\n",
    "\n",
    "        # get the class probability predictions and save them for validation\n",
    "        y_ = torch.softmax(y_pred, dim=1)\n",
    "        b = i * loader.batch_size\n",
    "        preds[b: b + y_.size(0), ...] = y_.argmax(dim=1).detach().cpu().numpy()\n",
    "        ys[b: b + y_.size(0), ...] = y.detach().cpu().numpy()\n",
    "    \n",
    "    # compute accuracy\n",
    "    d = dice(ys.flatten(), preds.flatten())\n",
    "    \n",
    "    # compute the average loss\n",
    "    loss_avg = loss_cum / cnt\n",
    "    \n",
    "    return loss_avg, d\n",
    "\n",
    "def train_net(net, train_loader, test_loader, loss_fn, optimizer, epochs, log_dir):\n",
    "    \n",
    "    # transfer the network to the GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    best_dice = 0\n",
    "    train_loss = np.zeros((epochs))\n",
    "    test_loss = np.zeros((epochs))\n",
    "    test_dice = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # training\n",
    "        train_loss[epoch] = train_epoch(net, train_loader, loss_fn, optimizer)\n",
    "        \n",
    "        # testing\n",
    "        test_loss[epoch], test_dice[epoch] = test_epoch(net, test_loader, loss_fn)\n",
    "\n",
    "        # check if accuracy has increased\n",
    "        if test_dice[epoch] > best_dice: \n",
    "            best_dice = test_dice[epoch]\n",
    "\n",
    "            # save the model\n",
    "            torch.save(net.state_dict(), 'unet_best.cpt')\n",
    "        \n",
    "        print('Epoch %5d - Train loss: %.6f - Test loss: %.6f - Test dice avg: %.6f' % (epoch, train_loss[epoch], test_loss[epoch], test_dice[epoch]))\n",
    "    \n",
    "    return train_loss, test_loss, test_dice\n",
    "\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "n_epochs = 20\n",
    "log_dir = '.'\n",
    "\n",
    "# define the optimizer\n",
    "class_weights = torch.from_numpy(np.divide(1, class_distribution)).float().to(device)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# start training\n",
    "train_loss_unet, test_loss_unet, test_dice_unet = train_net(net, train_loader, test_loader, loss_fn, optimizer, n_epochs, log_dir)\n",
    "\n",
    "# show the training curve and accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_cnn)\n",
    "plt.plot(test_loss_cnn)\n",
    "plt.plot(train_loss_unet)\n",
    "plt.plot(test_loss_unet)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(('Train (CNN)', 'Test (CNN)', 'Train (U-Net)', 'Test (U-Net)'))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_dice_cnn)\n",
    "plt.plot(test_dice_unet)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice avg')\n",
    "plt.legend(('CNN', 'U-Net'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUNhGHutGlm3"
   },
   "source": [
    "That should look much better! The U-Net architecture is significantly less suffering from overfitting and the mean Dice coefficient is substantially higher (should be approximately 0.90). \n",
    "\n",
    "Now let's have a look how the actual predictions look like. \n",
    "\n",
    "**Exercise**: Modify the `segment_slice` so that it segments a 2D image with a U-Net network: \n",
    "- Simplify the original code of `segment_slice` by propagating the image straightforward through the network. \n",
    "- Can you figure out why alternative image sizes can also be fed into the network? Is that always possible? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaJBgtsSlQwG"
   },
   "outputs": [],
   "source": [
    "def segment_slice(x, net):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# load the best parameters\n",
    "state_dict = torch.load('unet_best.cpt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# perform segmentation\n",
    "n = 0\n",
    "t = time.time()\n",
    "y_pred = segment_slice(x_test[n], net)\n",
    "print('Elapsed time: %.2f seconds' % (time.time() - t))\n",
    "\n",
    "# show example\n",
    "x_overlay = overlay(x_test[n], 1 - y_test[n], colors=[(1, 0, 0)], alpha=0.4)\n",
    "x_pred_overlay = overlay(x_test[n], 1 - y_pred, colors=[(1, 0, 0)], alpha=0.4)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_pred_overlay)\n",
    "plt.title('Predictions')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_overlay)\n",
    "plt.title('Labels')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQzbvxA6Hn8B"
   },
   "source": [
    "That is a much more usable segmentation result! Also note how much faster the segmentation computation is. The U-Net architecture excells in biomedical datasets because it can cope relatively well with small amounts of training data. If you have time left, you can always try to improve the results by adding data augmentation! "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020-dlb-3-cnn-segmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
