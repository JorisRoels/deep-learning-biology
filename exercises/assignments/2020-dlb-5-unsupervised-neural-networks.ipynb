{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSg5U4D5I35S"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JorisRoels/deep-learning-biology/blob/main/exercises/assignments/2020-dlb-5-unsupervised-neural-networks.ipynb)\n",
    "\n",
    "# Exercise 5: Unsupervised neural networks\n",
    "\n",
    "In this notebook, we will be see how autoencoders can be used for clustering and semi-supervised classification. \n",
    "\n",
    "The structure of these exercises is as follows: \n",
    "\n",
    "1. [Import libraries and download data](#scrollTo=ScagUEMTMjlK)\n",
    "2. [Data pre-processing](#scrollTo=ohZHyOTnI35b)\n",
    "3. [Building an autoencoder](#scrollTo=kIry8iFZI35y)\n",
    "4. [Clustering with autoencoders](#scrollTo=uXrEb0rTI35-)\n",
    "5. [Semi-supervised classification](#scrollTo=kEU34VvDUPr_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScagUEMTMjlK"
   },
   "source": [
    "## 1. Import libraries and download data\n",
    "Let's start with importing the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1oGi88ZU8eN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, metrics\n",
    "from progressbar import ProgressBar, Percentage, Bar, ETA, FileTransferSpeed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIPng9wbV-Zs"
   },
   "source": [
    "As you will notice, Colab environments come with quite a large library pre-installed. If you need to import a module that is not yet specified, you can add it in the previous cell (make sure to run it again). If the module is not installed, you can install it with `pip`. \n",
    "\n",
    "To make your work reproducible, it is advised to initialize all modules with stochastic functionality with a fixed seed. Re-running this script should give the same results as long as the seed is fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OOFPFLiV-mh"
   },
   "outputs": [],
   "source": [
    "# make sure the results are reproducible\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# run all computations on the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running computations with %s' % torch.device(device))\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohZHyOTnI35b"
   },
   "source": [
    "## 2. Data pre-processing\n",
    "\n",
    "We will use the well-known MNIST benchmarking dataset. This dataset is well-known in the world of machine learning. It consists of relatively small $28 \\times 28$ pixel images of digits. The goals of the dataset is to classify the digit images to the actual number that is on the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hJjZQEGI35f"
   },
   "outputs": [],
   "source": [
    "# batch size for the dataloader\n",
    "batch_size = 64\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, \n",
    "                   transform=transforms.ToTensor()), batch_size=batch_size, \n",
    "                   shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, download=True, \n",
    "                   transform=transforms.ToTensor()), batch_size=batch_size, \n",
    "                   shuffle=False)\n",
    "\n",
    "# print statistics\n",
    "print('The train data consists of %d samples' % len(train_loader.dataset))\n",
    "print('The test data consists of %d samples' % len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VChZ6dD9I35l"
   },
   "source": [
    "Here are a few examples of the data, the corresponding label is on top of each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8alfRhgtI35n"
   },
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(test_loader.dataset[i][0].numpy()[0, ...], cmap='gray')\n",
    "    plt.title(test_loader.dataset[i][1])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIry8iFZI35y"
   },
   "source": [
    "## 3. Building an autoencoder\n",
    "\n",
    "Now, we have to implement the autoencoder and train it. Let's start by defining the architecture. \n",
    "\n",
    "**Exercise**: build an autoencoder with a single hidden layer. Not that every pixel in the image corresponds to an input dimension, i.e. the input and output of the autoencoder will be $28 \\times 28$ dimensional and images will have to be reshaped in vector format. Implement the following architecture: \n",
    "- The first layer (encoder) will be a [fully connected layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) with [sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) activation that transforms the input features to a 64 dimensional (hidden) feature vector representation. \n",
    "- The second layer (decoder) is another [fully connected layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) that transforms the hidden representation to the original input dimensions. \n",
    "- Print the network architecture and propagate a test sample to validate your architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_gMrQN3VD10"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_input, dim_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "        return x\n",
    "\n",
    "dim_hidden = 64\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# propagate a sample\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# show the result\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEMW_Ss7ERHN"
   },
   "source": [
    "Time to train the network now! Remember, a single training iteration consists of the following steps: \n",
    "1. Construct a batch\n",
    "2. Zero the gradients\n",
    "3. Forward propagation\n",
    "4. Compute the loss\n",
    "5. Backward propagation\n",
    "6. Update the weights\n",
    "\n",
    "**Exercise**: train the autoencoder for 10 epochs on the data. \n",
    "- Map the autoencoder to the computing device\n",
    "- Define an Adam optimizer, with a learning rate of $10^{-2}$ and weight decay of $10^{-5}$\n",
    "- Define a mean squared error (MSE) loss function\n",
    "- Fill in the missing code in the `train_epoch` and `test_epoch` functions\n",
    "- Run the autoencoder on a sample and show the obtained reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8l0jAmOI356"
   },
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train_epoch(net, loader, optimizer, criterion, device): \n",
    "    net.train()\n",
    "    loss_avg = 0\n",
    "    for x, _ in loader:\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    loss_avg = loss_avg / len(loader)\n",
    "    return loss_avg\n",
    "\n",
    "# test for one epoch\n",
    "def test_epoch(net, loader, criterion, device): \n",
    "    net.eval()\n",
    "    loss_avg = 0\n",
    "    for x, _ in loader:\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    loss_avg = loss_avg / len(loader)\n",
    "    return loss_avg\n",
    "\n",
    "# train the autoencoder\n",
    "def train(net, train_loader, test_loader, optimizer, epochs, criterion, device): \n",
    "    train_losses = np.zeros((epochs))\n",
    "    test_losses = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        train_losses[epoch] = train_epoch(net, train_loader, optimizer, criterion, device)\n",
    "        test_losses[epoch] = test_epoch(net, test_loader, criterion, device)\n",
    "        print(\"Epoch %d/%d: Train loss = %.4f - Test loss = %.4f\" \n",
    "              % (epoch + 1, epochs, train_losses[epoch], test_losses[epoch]))\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "# parameters\n",
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "epochs = 10\n",
    "\n",
    "# computing device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# map the network to the device\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# optimizer\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# loss function\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# start training\n",
    "train_loss, test_loss = train(net_ae, train_loader, test_loader, \n",
    "                              optimizer, epochs, criterion, device)\n",
    "\n",
    "# visualize training result\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.legend(('Train', 'Test'))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSpJsSGrKUMB"
   },
   "outputs": [],
   "source": [
    "# propagate a sample\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# show the result\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXrEb0rTI35-"
   },
   "source": [
    "## 4. Clustering with autoencoders\n",
    "\n",
    "In this section, we will show you how you can cluster data with an autoencoder model. Perhaps the simplest approach is to cluster the data in the encoded space, e.g. using k-means clustering. \n",
    "\n",
    "**Exercise**: Cluster the MNIST test data using the encodings and k-means clustering\n",
    "- Compute the embeddings of the test data and store them in a numpy array\n",
    "- Apply k-means clustering on the embeddings\n",
    "- Evaluate the clustering with the [adjusted rand score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8H8AJGfjI35_"
   },
   "outputs": [],
   "source": [
    "def compute_embeddings(net, loader):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    return embeddings\n",
    "\n",
    "# compute the embeddings of the autoencoder on the test set\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# cluster the embeddings\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# evaluate\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52yu_pnXbOGf"
   },
   "source": [
    "The following code will compare the true labels and the clustering results. Note that the colors do not necessarily correspond to the same cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odUbcam-Wb8l"
   },
   "outputs": [],
   "source": [
    "# reduce the dimensionality of the hidden representations\n",
    "h_red = TSNE(n_components=2, random_state=seed).fit_transform(h[:1000])\n",
    "\n",
    "# visualize the reduced representations and label each sample\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(h_red[:, 0], h_red[:, 1], c=labels[:1000], cmap='Paired')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=range(10))\n",
    "plt.title('True labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(h_red[:, 0], h_red[:, 1], c=predictions[:1000], cmap='Paired')\n",
    "plt.title('Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TACB37JMbrl8"
   },
   "source": [
    "We will now focus towards the extracted features of the autoencoder. Within the encoder, there are connections to each pixel for each hidden variable. In other words, we can visualize which pixels are important to activate a particular hidden variable. \n",
    "\n",
    "**Exercise**: Visualize the extracted features based on the matrix weights from the encoder. \n",
    "- Extract the encoder matrix parameter values\n",
    "- For each hidden variable, reshape the corresponding features connected to the input to a $28 \\times 28$ image \n",
    "- Visualize all these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pd4QpjS5lO7N"
   },
   "outputs": [],
   "source": [
    "# extract the matrix parameters\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# visualize the features\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEU34VvDUPr_"
   },
   "source": [
    "## 5. Semi-supervised classification\n",
    "\n",
    "Semi-supervised classification aims to use large amounts of unlabeled data and a limited amount of labeled data for maximum classification performance. We will see that the extracted features of an autoencoder can serve as suitable features for classification. \n",
    "\n",
    "**Exercise**: Train and validate an SVM for increasing amounts of labeled training data. \n",
    "- Compute the embeddings of the train and test data. \n",
    "- Implement the `train_svm` function that trains an SVM with training $n$ samples. \n",
    "- Implement the `test_svm` function that tests an SVM on the complete test set and reports the accuracy. \n",
    "- Train an SVM for various amounts of labeled data with the autoencoder embeddings as input. \n",
    "- As a baseline, compare this approach to an SVM that is trained on the actual pixel values instead of the encodings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Azcb6-SlVUNv"
   },
   "outputs": [],
   "source": [
    "def train_svm(x_train, y_train, n):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    return clf\n",
    "\n",
    "def test_svm(clf, x_test, y_test):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    return acc\n",
    "\n",
    "# compute the embeddings of the autoencoder on the train and test set\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\"\n",
    "\n",
    "# train and test an SVM for a varying amount of training data\n",
    "n_train_min = 10\n",
    "n_train_max = 200\n",
    "n_train_step = 10\n",
    "n_samples = np.arange(n_train_min, n_train_max, n_train_step)\n",
    "accuracies_ae = np.zeros((len(n_samples)))\n",
    "accuracies_bl = np.zeros((len(n_samples)))\n",
    "for j in range(len(n_samples)):\n",
    "    # autoencoder\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    # baseline\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# visualize the results\n",
    "\"\"\"\n",
    "INSERT CODE HERE\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020-dlb-5-unsupervised-neural-networks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
