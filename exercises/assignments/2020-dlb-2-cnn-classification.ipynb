{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgIwhjJfXbmP"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JorisRoels/deep-learning-biology/blob/main/exercises/assignments/2020-dlb-2-cnn-classification.ipynb)\n",
    "\n",
    "# Exercise 2: Convolutional Neural Networks for Classification\n",
    "\n",
    "In this notebook, we will be using convolutional neural networks (CNN) to classify optical coherence tomography images for age-related macular degeneration and diabetic macular edema. \n",
    "\n",
    "The structure of these exercises is as follows: \n",
    "1. [Import libraries and download data](#scrollTo=Im6B91nkXCuW)\n",
    "2. [Data loading and augmentation](#scrollTo=P03i-jLJZQSy)\n",
    "3. [Training a CNN from scratch](#scrollTo=N_p6H2uV3vsn)\n",
    "4. [Visualizing the training progress with Tensorboard](#scrollTo=O_N-2Asp0RFp)\n",
    "5. [Finetuning a pre-trained CNN](#scrollTo=hCfqPkf27lMK)\n",
    "\n",
    "This notebook is largely based on the research published in: \n",
    "\n",
    "Kermany, D. S., Goldbaum, M., Cai, W., Valentim, C. C. S., Liang, H., Baxter, S. L., McKeown, A., Yang, G., Wu, X., Yan, F., Dong, J., Prasadha, M. K., Pei, J., Ting, M., Zhu, J., Li, C., Hewett, S., Dong, J., Ziyar, I., â€¦ Zhang, K. (2018). Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell, 172(5), 1122-1131.e9. https://doi.org/10.1016/j.cell.2018.02.010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im6B91nkXCuW"
   },
   "source": [
    "## 1. Import libraries and download data\n",
    "As usual, we import the necessary libraries and download the required data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRtYVPx1XFkR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, RandomRotation, RandomHorizontalFlip, ToTensor, Normalize\n",
    "import torchvision.models as models\n",
    "import gdown\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpcAbbM7XCdd"
   },
   "source": [
    "As you will notice, Colab environments come with quite a large library pre-installed. If you need to import a module that is not yet specified, you can add it in the previous cell (make sure to run it again). If the module is not installed, you can install it with `pip`. \n",
    "\n",
    "To make your work reproducible, it is advised to initialize all modules with stochastic functionality with a fixed seed. Re-running this script should give the same results as long as the seed is fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_3cnRGMXPm1"
   },
   "outputs": [],
   "source": [
    "# make sure the results are reproducible\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# run all computations on the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running computations with %s' % torch.device(device))\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nUtus7CXQyJ"
   },
   "source": [
    "We will now download the required data from a public Google Drive repository. The data is stored as a zip archive and automatically extracted to the `data` directory in the current directory. \n",
    "\n",
    "Note that, for the sake of practicality in this workshop, we have only provided a fraction of the full dataset (approximately 15% of the complete dataset). This is due to disk limitations on Google Colab, but perhaps mostly to limit the computational bottleneck. Feel free to test this approach on the complete dataset (available here) on an alternative compute environment! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kr9WbGJtXTAd"
   },
   "outputs": [],
   "source": [
    "# fields\n",
    "url = 'http://data.bits.vib.be/pub/trainingen/DeepLearning/data-2.zip'\n",
    "cmp_data_path = 'data.zip'\n",
    "\n",
    "# download the compressed data\n",
    "gdown.download(url, cmp_data_path, quiet=False)\n",
    "\n",
    "# extract the data\n",
    "zip = zipfile.ZipFile(cmp_data_path)\n",
    "zip.extractall('')\n",
    "\n",
    "# remove the compressed data\n",
    "os.remove(cmp_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P03i-jLJZQSy"
   },
   "source": [
    "## 2. Data loading and augmentation\n",
    "\n",
    "Let's visualize an image of each class in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcOSKSfzm5kO"
   },
   "outputs": [],
   "source": [
    "# list of the classes\n",
    "classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "class_distribution = np.zeros((4,))\n",
    "for i, c in enumerate(classes):\n",
    "\n",
    "  # get a list of all files in this class directory\n",
    "  files = os.listdir(os.path.join('data-2/OCT/train', c))\n",
    "\n",
    "  # get a random sample\n",
    "  filename = files[np.random.randint(len(files))]\n",
    "\n",
    "  # print stats\n",
    "  class_distribution[i] = len(files)\n",
    "  print('Class %s has %d images' % (c, len(files)))\n",
    "\n",
    "  # load the image\n",
    "  image = Image.open(os.path.join(os.path.join('data-2/OCT/train', c, filename)))\n",
    "\n",
    "  # show the image\n",
    "  plt.subplot(2, 2, i + 1)\n",
    "  plt.imshow(image, cmap='gray')\n",
    "  plt.axis('off')\n",
    "  plt.title(c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OdqTqhkr01p"
   },
   "source": [
    "For most machine learning applications, normalization is a valuable pre-processing step. Fortunately, this can be easily done in PyTorch through dataloaders. You might have noticed that a very simple dataloader was already implemented in the previous exercises. Now, you will implement this yourself! \n",
    "\n",
    "A dataloader instance uses a dataset to sample batches that can be used for training and testing. Additionally, dataloaders allow very efficient usage of so-called data augmentation. This is a way of generating more labeled data using transformations such as rotations, scaling, shifts, etc. so that the model generalizes better. Labeled data is typically hard to obtain due to the fact that labels are expensive or time-consuming to generate. This is especially the case in the biomedical domain where often also expertise is required. As a consequence, models often overfit on the training data itself. To improve generalization, it is common practice to apply data augmentation, i.e. transform the data in a way that do not change the labels. Typical transformations are rotations, mirroring, scaling, random deformations, etc. \n",
    "\n",
    "A dataset class should implement two functions: a `__getitem__` function that selects the $i$th instance and a `__len__` function that returns the amount of samples in the dataset. \n",
    "\n",
    "**Exercise**: Implement the `MedicalDataset` class: \n",
    "- The `__init__` function has already been implemented and loads the train/test data from a specific directory. The data are stored in `MedicalDataset.data`, which is a list of [Pillow Image](https://pillow.readthedocs.io/en/stable/reference/Image.html) objects. The corresponding labels are stored in `MedicalDataset.labels`, which is a list of integer labels. Note that the data is resized to 64 x 64 pixel images. This is for computational convenience, you can later increase this to the original size and analyze the results. \n",
    "- Implement the `__getitem__` function: this should return the $i$th image and its corresponding label als a tuple. \n",
    "- Implement the `__len__` function: this should return the amount of samples in the dataset. \n",
    "- Include data augmentation while sampling from the dataset, i.e. in the `__getitem__` function. You can apply small [rotations](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomRotation) and [horizontal flips](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomHorizontalFlip) on the data. Note that you can deal with any kind of pre-processing problem here. For example, the should be [normalized](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) and [converted to PyTorch tensors](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor). The mean and standard deviation of the instensity values is approximately 0.1706 and 0.1841. Make sure you [compose](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Compose) these augmentations in the right order! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJCAj-0SdeVs"
   },
   "outputs": [],
   "source": [
    "\n",
    "# implementation of a dataset that will be used for training\n",
    "class MedicalDataset(data.Dataset):\n",
    "\n",
    "  def __init__(self, top_dir, augmenter=None, input_shape=(256, 256)):\n",
    "    \n",
    "    # useful fields\n",
    "    self.top_dir = top_dir\n",
    "    self.classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "    self.input_shape = input_shape\n",
    "    self.augmenter = augmenter\n",
    "\n",
    "    # logging\n",
    "    print('Start loading %s' % self.top_dir)\n",
    "\n",
    "    # load the data\n",
    "    self.data = []\n",
    "    self.labels = []\n",
    "    for i, c in enumerate(classes):\n",
    "\n",
    "      # get a list of all files in this class directory\n",
    "      files = os.listdir(os.path.join(top_dir, c))\n",
    "\n",
    "      # logging\n",
    "      print('  Loading class %s' % c)\n",
    "\n",
    "      # load all files\n",
    "      for filename in files:\n",
    "\n",
    "        # load image\n",
    "        x = Image.open(os.path.join(os.path.join(top_dir, c, filename)))\n",
    "\n",
    "        # save as 8-bit gray scale images\n",
    "        x = x.convert(mode='L')\n",
    "\n",
    "        # resize images for memory limitations\n",
    "        x = x.resize(input_shape)\n",
    "\n",
    "        # save the image and corresponding label\n",
    "        self.data.append(x)\n",
    "        self.labels.append(i)\n",
    "  \n",
    "  def __getitem__(self, i):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "  \n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "# fixed input shape for the network\n",
    "input_shape = (64, 64)\n",
    "\n",
    "# define the data augmenter\n",
    "augmenter_train = Compose([RandomRotation(20), RandomHorizontalFlip(), ToTensor(), Normalize(0.1706, 0.1841)])\n",
    "augmenter_test = Compose([ToTensor(), Normalize(0.1706, 0.1841)])\n",
    "\n",
    "# make an instance of the dataset for training and testing\n",
    "ds_train = MedicalDataset('data-2/OCT/train', augmenter=augmenter_train, input_shape=input_shape)\n",
    "ds_test = MedicalDataset('data-2/OCT/test', augmenter=augmenter_test, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-z0pkXokASF"
   },
   "source": [
    "Extracting labeled samples now becomes very easy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d29DkZuFhQ3N"
   },
   "outputs": [],
   "source": [
    "# extract a labeled sample\n",
    "print('There are %d training samples' % len(ds_train))\n",
    "print('There are %d testing samples' % len(ds_test))\n",
    "n = np.random.randint(len(ds_test))\n",
    "x, y = ds_test[n]\n",
    "print('The selected sample is %s dimensional' % list(x.size()))\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(classes[y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVlH4XCVkwrc"
   },
   "source": [
    "This is a quick illustration of the data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SUwEBfimtGd"
   },
   "outputs": [],
   "source": [
    "# apply augmentation on a random sample\n",
    "image_ = augmenter_train(image)\n",
    "\n",
    "# show images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Augmented image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPB9eMBgoR0d"
   },
   "source": [
    "Great, now the only thing we have to do in order to handle batching is to wrap the dataset in a dataloader object that specifies the desired batch size! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMOvfQllocFX"
   },
   "outputs": [],
   "source": [
    "# desired batch size\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_p6H2uV3vsn"
   },
   "source": [
    "## 3. Training a CNN from scratch\n",
    "\n",
    "Not that we have dealt with data loading and augmentation, we are ready to define a network architecture. \n",
    "\n",
    "**Exercise**: Implement the `MedicalNet` class: \n",
    "- Similar to the previous exercise, a Module extension should have an initialization and a forward propagation function (respectively `__init__` and `forward`). The initialization function should initialize the required convolutional layers, activation functions, batch normalization, etc. \n",
    "- Construct a CNN with 6 [convolutional layers](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) (you can choose a fixed amount of feature maps). Each convolutional layer should be followed by a [batch normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d), [ReLU activation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) and [max pooling](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) layer. The final features then have to be [flattened](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and propagated to a [linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) (fully connected) layer that generates the logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVqQhf1g3vV4"
   },
   "outputs": [],
   "source": [
    "class MedicalNet(nn.Module):\n",
    "    def __init__(self, feature_maps=16):\n",
    "        super(MedicalNet, self).__init__()\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "net = MedicalNet(feature_maps=16)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoEWNi1P3vM5"
   },
   "source": [
    "Next, we need to define a loss function to train the classifier. Similar to the previous exercise, we employ the cross entropy function. More specifically, since the data is imbalanced, we will use the following weights to balance the class importances: \n",
    "$$\n",
    "w_c=\\frac{n}{\\left| \\left\\{ i | y_i = c \\right\\} \\right|}\n",
    "$$\n",
    "where $n$ is the amount of training samples. In other words, we employ the inverse class frequencies for weight balancing. For the optimization, we employ the Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iRPZ9ER3wUg"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "class_weights = torch.from_numpy(np.divide(1, class_distribution)).float().to(device)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "for i, c in enumerate(classes):\n",
    "  print('Weight for class %s: %f' % (c, class_weights.cpu().numpy()[i]))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOL_uZHA3s5Q"
   },
   "source": [
    "Now we can train the CNN with stochastic gradient descent. \n",
    "\n",
    "**Exercise**: Train the CNN for classification of the medical images: \n",
    "- Below is skeleton code that you might recognize from the previous exercise. Implement the missing code snippets to train the CNN. \n",
    "- Compute the accuracy of the classifier at the end of each test epoch. \n",
    "- Keep track of the best performing method (w.r.t. the test accuracy) and [save this model](https://pytorch.org/tutorials/beginner/saving_loading_models.html). The recommended way of doing this, is by using the [`torch.save`](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save) function on the state dictionary of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oC8PmuLCXoPR"
   },
   "outputs": [],
   "source": [
    "state_dict = net.state_dict()\n",
    "for k in state_dict.keys():\n",
    "  print('Key: %s - Parameter shape: %s' % (k, state_dict[k].size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3by3eCfHXo74"
   },
   "source": [
    "- This dictionary efficiently groups the parameters of the model together and gives the best guarantee that you will be able to load your custom network later. At the end of training, load the best performing network using [`torch.load`](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load) and visualize the confusion matrix on the test data with the provided validation function. Note that `torch.load` loads a state dictionary, this is not yet a network module! You will have to call the [`load_state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict) method to load the parameters in the existing network instance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kE44xaS3scM"
   },
   "outputs": [],
   "source": [
    "def validate_net(net, loader):\n",
    "    \n",
    "    # set the network in training mode\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    \n",
    "    # keep track of the loss and predictions\n",
    "    preds = np.zeros((len(loader.dataset), 4))\n",
    "    \n",
    "    for i, data in enumerate(loader): \n",
    "        \n",
    "        # sample data\n",
    "        x, y = data\n",
    "\n",
    "        # transfer data to GPU and correct format\n",
    "        x = x.float().to(device)\n",
    "        \n",
    "        # feed the batch to the network and compute the outputs\n",
    "        y_pred = net(x)\n",
    "\n",
    "        # get the class probability predictions and save them for validation\n",
    "        y_ = torch.softmax(y_pred, dim=1)\n",
    "        b = i * loader.batch_size\n",
    "        preds[b: b + y_.size(0), :] = y_.detach().cpu().numpy()\n",
    "    \n",
    "    # compute accuracy\n",
    "    y = np.array(loader.dataset.labels)\n",
    "    acc = accuracy_score(y, preds.argmax(axis=1))\n",
    "    print('Accuracy: %.1f' % (acc*100))\n",
    "    conf_matrix = confusion_matrix(y, preds.argmax(axis=1), normalize='true')\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, classes).plot()\n",
    "\n",
    "# implementation of a single training epoch\n",
    "def train_epoch(net, loader, loss_fn, optimizer):\n",
    "    \n",
    "    # set the network in training mode\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    # keep track of the loss\n",
    "    loss_cum = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    bar = progressbar.ProgressBar(max_value=len(loader.dataset))\n",
    "    for i, data in enumerate(loader): \n",
    "        # update progressbar\n",
    "        bar.update(i * loader.batch_size)\n",
    "        \n",
    "        # sample data\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "        # transfer data to GPU and correct format\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        \n",
    "        # set all gradients equal to zero\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        \n",
    "        # feed the batch to the network and compute the outputs\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        \n",
    "        # compare the outputs to the labels with the loss function\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_cum += loss.data.cpu().numpy()\n",
    "        cnt += 1\n",
    "        \n",
    "        # backpropagate the gradients w.r.t. computed loss\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "        # apply one step in the optimization\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "    \n",
    "    # compute the average loss\n",
    "    loss_avg = loss_cum / cnt\n",
    "    \n",
    "    return loss_avg\n",
    "\n",
    "# implementation of a single testing epoch\n",
    "def test_epoch(net, loader, loss_fn):\n",
    "    \n",
    "    # set the network in training mode\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    # keep track of the loss and predictions\n",
    "    preds = np.zeros((len(loader.dataset), 4))\n",
    "    loss_cum = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, data in enumerate(loader): \n",
    "        \n",
    "        # sample data\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "        # transfer data to GPU and correct format\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        \n",
    "        # feed the batch to the network and compute the outputs\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        \n",
    "        # compare the outputs to the labels with the loss function\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_cum += loss.data.cpu().numpy()\n",
    "        cnt += 1\n",
    "\n",
    "        # get the class probability predictions and save them for validation\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "    \n",
    "    # compute accuracy\n",
    "    \"\"\"\n",
    "    INSERT CODE HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the average loss\n",
    "    loss_avg = loss_cum / cnt\n",
    "    \n",
    "    return loss_avg, acc\n",
    "\n",
    "def train_net(net, train_loader, test_loader, loss_fn, optimizer, epochs, log_dir):\n",
    "    \n",
    "    # transfer the network to the GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # training\n",
    "        train_loss = train_epoch(net, train_loader, loss_fn, optimizer)\n",
    "        \n",
    "        # testing\n",
    "        test_loss, acc = test_epoch(net, test_loader, loss_fn)\n",
    "\n",
    "        # check if accuracy has increased\n",
    "        if acc > best_acc: \n",
    "            best_acc = acc\n",
    "\n",
    "            # save the model\n",
    "            torch.save(net.state_dict(), 'medicalnet_best.cpt')\n",
    "        \n",
    "        print('Epoch %5d - Train loss: %.6f - Test loss: %.6f' % (epoch, train_loss, test_loss))\n",
    "\n",
    "# parameters\n",
    "n_epochs = 10\n",
    "log_dir = '.'\n",
    "\n",
    "# start training\n",
    "train_net(net, train_loader, test_loader, loss_fn, optimizer, n_epochs, log_dir)\n",
    "\n",
    "# load the best parameters\n",
    "state_dict = torch.load('medicalnet_best.cpt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# validate with confusion plot\n",
    "validate_net(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_N-2Asp0RFp"
   },
   "source": [
    "## 4. Visualizing the training progress with TensorBoard\n",
    "\n",
    "Debugging CNNs can be tricky, because they are essentially black boxes and it is difficult for us to find out what they are exactly doing during training. To simplify training for developers, researchers at Google have developed TensorBoard. Even though this is a platform embedded in TensorFlow, an alternative to PyTorch, it is perfectly possible to use the tool to aid training visualization. \n",
    "\n",
    "TensorBoard uses a binary .events file to save training logs such as scalars, images, histograms, etc. This file is continuesly read, parsed and visualized in the TensorBoard UI. To launch TensorBoard in a Colab notebook, you first have to load the extension and run the executable with the logging directory that contains this .events file as an argument. Note that you will not have to load the tensorboard extension on your local workstation. If you have correctly installed TensorBoard, the executable should be within reach in your local environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zswWAasOerOv"
   },
   "outputs": [],
   "source": [
    "# load the extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e64Zp7jbSuAR"
   },
   "outputs": [],
   "source": [
    "# launch tensorboard\n",
    "%tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlDqQm2G2nve"
   },
   "source": [
    "Obviously, as we have not yet written any data to the logging directory, the TensorBoard UI will be completely empty. Let's change this! \n",
    "\n",
    "**Exercise**: Log useful information to TensorBoard: \n",
    "- To log data such as scalar values to TensorBoard from within PyTorch, you can use the [tensorboard](https://pytorch.org/docs/stable/tensorboard.html) utility module. You can initialize an .events file by making a [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter) object. This requires you to specify a logging directory where you would like to store the .events file. This should be the same directory as the one used to launch TensorBoard. \n",
    "- Modify the training code by logging the train and test loss, and the test accuracy. You can do this using the [`add_scalar`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar) method of `SummaryWriter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqHguq0YTV30"
   },
   "outputs": [],
   "source": [
    "# re-initialize the network\n",
    "net = MedicalNet(feature_maps=16)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# parameters\n",
    "n_epochs = 10\n",
    "log_dir = '.'\n",
    "\n",
    "# start training\n",
    "train_net(net, train_loader, test_loader, loss_fn, optimizer, n_epochs, log_dir)\n",
    "\n",
    "# load the best parameters\n",
    "state_dict = torch.load('medicalnet_best.cpt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# validate with confusion plot\n",
    "validate_net(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCfqPkf27lMK"
   },
   "source": [
    "## 5. Finetuning a pre-trained CNN\n",
    "\n",
    "As you re-initialize a network and train it, you will notice that the performance might vary. Especially in absence of large amounts of training data, the performance results can be either instable or insufficient. A common strategy to improve these aspects is to employ a pre-trained feature extractor and finetune the remaining classification layers. PyTorch offers a large set of pre-trained neural networks, a list can be found [here](https://pytorch.org/docs/stable/torchvision/models.html). \n",
    "\n",
    "**Exercise**: Implement a classification model, based on a fixed, pre-trained feature extractor: \n",
    "- Implement the `PTMedicalNet` class: the architecture of the network should consist of a feature extractor (e.g. ResNet18) and a classifier. In other words, you will have to take the feature extractor of a pretrained network and attach a fully connected layer to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su_AD2q0--cR"
   },
   "outputs": [],
   "source": [
    "class PTMedicalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PTMedicalNet, self).__init__()\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        INSERT CODE HERE\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "net = PTMedicalNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etJs_xf6ENE3"
   },
   "outputs": [],
   "source": [
    "# desired batch size\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=batch_size)\n",
    "\n",
    "# re-initialize the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# parameters\n",
    "n_epochs = 10\n",
    "log_dir = '.'\n",
    "\n",
    "# start training\n",
    "train_net(net, train_loader, test_loader, loss_fn, optimizer, n_epochs, log_dir)\n",
    "\n",
    "# load the best parameters\n",
    "state_dict = torch.load('medicalnet_best.cpt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# validate with confusion plot\n",
    "validate_net(net, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMI7aCRRc5GV57gsE5L6QLS",
   "collapsed_sections": [],
   "name": "2020-dlb-2-cnn-classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
